{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC4m9EyJbTQr"
   },
   "source": [
    "# MSOA level segmentation of London to aid decision making in choosing an ideal location for a new restaurant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "1. Remove unnecessary columns\n",
    "2. <strike>Add wordCloud cluster analysis....</strike>\n",
    "3. <strike>Add new tooltip template</strike>\n",
    "    1. All relevant stats, including clusters\n",
    "1. <strike>Analyse optimal cluster </strike>\n",
    "4. Write narrative\n",
    "5. Revise mips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhauBkl_cIMx"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94xPYNaycIP1"
   },
   "source": [
    "## Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JzQMeZ1cISr"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrL3GgC3cIVa"
   },
   "source": [
    "### Used datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjLokcQzcNWQ"
   },
   "source": [
    "## Applied techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvwFwn3xcNZI"
   },
   "source": [
    "## Results and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWtJzQtvcNbv"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPcMof-acNdx"
   },
   "source": [
    "# Installation and importing of the used python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlwmNwhgchDU"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da-I1-7RcChJ",
    "outputId": "787ae741-1777-4184-fb08-7c96e1d96332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in c:\\program files\\python38\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: requests in c:\\program files\\python38\\lib\\site-packages (from folium) (2.23.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\program files\\python38\\lib\\site-packages (from folium) (2.11.2)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (from folium) (1.18.2)\n",
      "Requirement already satisfied: branca>=0.3.0 in c:\\program files\\python38\\lib\\site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\program files\\python38\\lib\\site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python38\\lib\\site-packages (from requests->folium) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\program files\\python38\\lib\\site-packages (from requests->folium) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\program files\\python38\\lib\\site-packages (from requests->folium) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\program files\\python38\\lib\\site-packages (from requests->folium) (2.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\program files\\python38\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (7.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (1.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\program files\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\program files\\python38\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\program files\\python38\\lib\\site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in c:\\program files\\python38\\lib\\site-packages (from plotly) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\program files\\python38\\lib\\site-packages (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\program files\\python38\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\program files\\python38\\lib\\site-packages (from bs4) (4.9.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\program files\\python38\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: openpyxl in c:\\program files\\python38\\lib\\site-packages (3.0.6)\n",
      "Requirement already satisfied: jdcal in c:\\program files\\python38\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\program files\\python38\\lib\\site-packages (from openpyxl) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\program files\\python38\\lib\\site-packages (3.2.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\program files\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python38\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\python38\\lib\\site-packages (from pandas) (1.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python38\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\program files\\python38\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (3.2.1)\n",
      "Requirement already satisfied: pillow in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (7.1.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\program files\\python38\\lib\\site-packages (from wordcloud) (1.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python38\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\program files\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (1.18.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\program files\\python38\\lib\\site-packages (7.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\program files\\python38\\lib\\site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\program files\\python38\\lib\\site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\program files\\python38\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\program files\\python38\\lib\\site-packages (from ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\program files\\python38\\lib\\site-packages (from ipywidgets) (7.13.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\program files\\python38\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.3)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\program files\\python38\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: decorator in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pygments in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (41.2.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\program files\\python38\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\program files\\python38\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\program files\\python38\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\program files\\python38\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\program files\\python38\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\program files\\python38\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\program files\\python38\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\program files\\python38\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: wcwidth in c:\\program files\\python38\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.1.9)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\program files\\python38\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (19.0.0)\n",
      "Requirement already satisfied: nbconvert in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.1)\n",
      "Requirement already satisfied: Send2Trash in c:\\program files\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files\\python38\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\program files\\python38\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\program files\\python38\\lib\\site-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\program files\\python38\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: testpath in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: bleach in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.4)\n",
      "Requirement already satisfied: defusedxml in c:\\program files\\python38\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: webencodings in c:\\program files\\python38\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyclustertend in c:\\program files\\python38\\lib\\site-packages (1.4.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install folium\n",
    "!pip install wordcloud\n",
    "!pip install plotly\n",
    "!pip install xlrd\n",
    "!pip install bs4\n",
    "!pip install openpyxl\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install wordcloud\n",
    "!pip install numpy\n",
    "!pip install ipywidgets\n",
    "!pip install pyclustertend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr45xdcucy4-"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T3RaSIEQcgA-"
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "import requests\n",
    "import plotly\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyclustertend import hopkins\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JgpCqkKc8rk"
   },
   "source": [
    "# Constants, configuration and initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zj1TZ56Mc38N"
   },
   "outputs": [],
   "source": [
    "LONDON_COORDS = [51.5074, 0.1278]\n",
    "\n",
    "#### setting default figure size for our convenience\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 20, 10\n",
    "\n",
    "#### changing style of matplotlib\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "#### dictionary for the urls\n",
    "urls = dict()\n",
    "\n",
    "#### dictionary for the dataframes\n",
    "\n",
    "dfs = dict()\n",
    "maps = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kf_hJaWqh1eI"
   },
   "source": [
    "## Data sources (URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xGF5ALX9h4ev"
   },
   "outputs": [],
   "source": [
    "urls[\"MSOA_ETH_2011\"] = \"https://data.parliament.uk/resources/constituencystatistics/Ethnic-group.xlsx\"\n",
    "\n",
    "urls[\"MSOA_INCOME_2018\"] = \"https://www.ons.gov.uk/file?uri=%2femploymentandlabourmarket%2fpeopleinwork%2fearningsandworkinghours%2fdatasets%2fsmallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales%2ffinancialyearending2018/totalannualincome2018.csv\"\n",
    "\n",
    "urls[\"MSOA_TO_LSOA_MAPPING\"] = \"https://opendata.arcgis.com/datasets/fe6c55f0924b4734adf1cf7104a0173e_0.csv\"\n",
    "\n",
    "urls[\"MSOA_POP_WEIGHTED_COORDS\"] = \"https://opendata.arcgis.com/datasets/b0a6d8a3dc5d4718b3fd62c548d60f81_0.geojson\"\n",
    "urls[\"LSOA_AVERAGE_RENTS\"] = \"https://data.london.gov.uk/download/average-private-rents-borough/73b9fb07-b5bb-4a53-88b7-c17269879a08/voa-average-rent-borough.xls\"\n",
    "\n",
    "urls[\"MSOA_GSON\"] = \"https://opendata.arcgis.com/datasets/826dc85fb600440889480f4d9dbb1a24_1.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOyN_lWBiPZI"
   },
   "source": [
    "# Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oJ92GZUi1Au"
   },
   "source": [
    "## Obtaining ethnical data of UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "DSqQC25hipmy",
    "outputId": "01630911-4aa4-4118-a736-e1583bbee397"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ONSConstID</th>\n",
       "      <th>ConstituencyName</th>\n",
       "      <th>MSOAID</th>\n",
       "      <th>MSOAName</th>\n",
       "      <th>DateThisUpdate</th>\n",
       "      <th>DateOfDataset</th>\n",
       "      <th>PopWhiteNbhdNum</th>\n",
       "      <th>PopMixedNbhdNum</th>\n",
       "      <th>PopAsianNbhdNum</th>\n",
       "      <th>PopBlackNbhdNum</th>\n",
       "      <th>PopOtherNbhdNum</th>\n",
       "      <th>PopWhiteNbhd%</th>\n",
       "      <th>PopMixedNbhd%</th>\n",
       "      <th>PopAsianNbhd%</th>\n",
       "      <th>PopBlackNbhd%</th>\n",
       "      <th>PopOtherNbhd%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E14000530</td>\n",
       "      <td>Aldershot</td>\n",
       "      <td>E02004753</td>\n",
       "      <td>Blackwater, Frogmore &amp; Minley</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>2011</td>\n",
       "      <td>9368</td>\n",
       "      <td>161</td>\n",
       "      <td>402</td>\n",
       "      <td>137</td>\n",
       "      <td>47</td>\n",
       "      <td>0.926149</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E14000530</td>\n",
       "      <td>Aldershot</td>\n",
       "      <td>E02004802</td>\n",
       "      <td>Hawley Lane &amp; Fox Lane</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>2011</td>\n",
       "      <td>5709</td>\n",
       "      <td>141</td>\n",
       "      <td>887</td>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>0.832944</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.129413</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.005836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E14000530</td>\n",
       "      <td>Aldershot</td>\n",
       "      <td>E02004803</td>\n",
       "      <td>Mayfield</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>2011</td>\n",
       "      <td>5603</td>\n",
       "      <td>229</td>\n",
       "      <td>1499</td>\n",
       "      <td>153</td>\n",
       "      <td>68</td>\n",
       "      <td>0.741923</td>\n",
       "      <td>0.030323</td>\n",
       "      <td>0.198490</td>\n",
       "      <td>0.020260</td>\n",
       "      <td>0.009004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ONSConstID ConstituencyName     MSOAID                       MSOAName  \\\n",
       "0  E14000530        Aldershot  E02004753  Blackwater, Frogmore & Minley   \n",
       "1  E14000530        Aldershot  E02004802         Hawley Lane & Fox Lane   \n",
       "2  E14000530        Aldershot  E02004803                       Mayfield   \n",
       "\n",
       "  DateThisUpdate  DateOfDataset  PopWhiteNbhdNum  PopMixedNbhdNum  \\\n",
       "0     2020-11-12           2011             9368              161   \n",
       "1     2020-11-12           2011             5709              141   \n",
       "2     2020-11-12           2011             5603              229   \n",
       "\n",
       "   PopAsianNbhdNum  PopBlackNbhdNum  PopOtherNbhdNum  PopWhiteNbhd%  \\\n",
       "0              402              137               47       0.926149   \n",
       "1              887               77               40       0.832944   \n",
       "2             1499              153               68       0.741923   \n",
       "\n",
       "   PopMixedNbhd%  PopAsianNbhd%  PopBlackNbhd%  PopOtherNbhd%  \n",
       "0       0.015917       0.039743       0.013544       0.004647  \n",
       "1       0.020572       0.129413       0.011234       0.005836  \n",
       "2       0.030323       0.198490       0.020260       0.009004  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = dict()\n",
    "dfs[\"MSOA_ETH_2011\"] = pd.read_excel(urls[\"MSOA_ETH_2011\"], sheet_name = \"Neighbourhood data\")\n",
    "dfs[\"MSOA_ETH_2011\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_ETH_2011\"][\"total_population\"] = dfs[\"MSOA_ETH_2011\"][[\"PopWhiteNbhdNum\", \"PopMixedNbhdNum\", \"PopAsianNbhdNum\", \"PopBlackNbhdNum\", \"PopOtherNbhdNum\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbPVGeYri9Q4"
   },
   "source": [
    "### Filtering the Dataframe to relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YWBHNFzi4xx",
    "outputId": "1c7fc794-5ca1-425d-85be-9bdd7834db20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:4125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs[\"MSOA_ETH_2011_mod\"] = dfs[\"MSOA_ETH_2011\"][[\"MSOAID\",\"total_population\",\n",
    "                                                 \"PopAsianNbhd%\"]]\n",
    "dfs[\"MSOA_ETH_2011_mod\"].rename(columns = {'MSOAID': \"msoa11cd\",\n",
    "                                       \"PopAsianNbhd%\": \"asian_population_percentage\"\n",
    "                                       }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msoa11cd</th>\n",
       "      <th>total_population</th>\n",
       "      <th>asian_population_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E02004753</td>\n",
       "      <td>10115</td>\n",
       "      <td>0.039743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E02004802</td>\n",
       "      <td>6854</td>\n",
       "      <td>0.129413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E02004803</td>\n",
       "      <td>7552</td>\n",
       "      <td>0.198490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    msoa11cd  total_population  asian_population_percentage\n",
       "0  E02004753             10115                     0.039743\n",
       "1  E02004802              6854                     0.129413\n",
       "2  E02004803              7552                     0.198490"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"MSOA_ETH_2011_mod\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y8fEMfNjVo_"
   },
   "source": [
    "## Obtaining income data of UK\n",
    "This proved to be a bit trickier since by default, non-browser requests are blocked from the source domain. Therefore, the requests library was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "RddcT32xjY86",
    "outputId": "f27d8c0f-162f-4abf-ef25-51ec8af9f13b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSOA code</th>\n",
       "      <th>MSOA name</th>\n",
       "      <th>Local authority code</th>\n",
       "      <th>Local authority name</th>\n",
       "      <th>Region code</th>\n",
       "      <th>Region name</th>\n",
       "      <th>Total annual income (Ł)</th>\n",
       "      <th>Upper confidence limit (Ł)</th>\n",
       "      <th>Lower confidence limit (Ł)</th>\n",
       "      <th>Confidence interval (Ł)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E02004297</td>\n",
       "      <td>County Durham 001</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>39,800</td>\n",
       "      <td>47,800</td>\n",
       "      <td>33,100</td>\n",
       "      <td>14,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E02004290</td>\n",
       "      <td>County Durham 002</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>42,200</td>\n",
       "      <td>50,700</td>\n",
       "      <td>35,200</td>\n",
       "      <td>15,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E02004298</td>\n",
       "      <td>County Durham 003</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>40,100</td>\n",
       "      <td>48,000</td>\n",
       "      <td>33,400</td>\n",
       "      <td>14,600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSOA code          MSOA name Local authority code Local authority name  \\\n",
       "0  E02004297  County Durham 001            E06000047        County Durham   \n",
       "1  E02004290  County Durham 002            E06000047        County Durham   \n",
       "2  E02004298  County Durham 003            E06000047        County Durham   \n",
       "\n",
       "  Region code Region name Total annual income (Ł) Upper confidence limit (Ł)  \\\n",
       "0   E12000001  North East                  39,800                     47,800   \n",
       "1   E12000001  North East                  42,200                     50,700   \n",
       "2   E12000001  North East                  40,100                     48,000   \n",
       "\n",
       "  Lower confidence limit (Ł) Confidence interval (Ł)  \n",
       "0                     33,100                  14,700  \n",
       "1                     35,200                  15,500  \n",
       "2                     33,400                  14,600  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faking_browser = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0'}\n",
    "req = requests.get(urls[\"MSOA_INCOME_2018\"], headers = faking_browser)\n",
    "io_buff = io.BytesIO(req.content)\n",
    "dfs[\"MSOA_INCOME_2018\"] = pd.read_csv(io_buff, skiprows = 4, encoding= \"ISO8859-2\")\n",
    "dfs[\"MSOA_INCOME_2018\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4746SXUAjuQC"
   },
   "source": [
    "### Filtering the Dataframe to relevant features\n",
    "Additionally, the result set will be limited to MSOA ID's whose parent region is London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mQCPG0Toju0y"
   },
   "outputs": [],
   "source": [
    "dfs[\"MSOA_INCOME_2018_mod\"] =\\\n",
    " dfs[\"MSOA_INCOME_2018\"][dfs[\"MSOA_INCOME_2018\"][\"Region name\"].str.match(\"London\")]\n",
    "dfs[\"MSOA_INCOME_2018_mod\"] = dfs[\"MSOA_INCOME_2018_mod\"]\\\n",
    "[[\"MSOA code\", \"Region name\", \"Total annual income (Ł)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I78wgzp_pVZ_",
    "outputId": "7b57c049-21c8-4b4f-8837-22e95120a17d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"MSOA_INCOME_2018_mod\"][\"Total annual income (Ł)\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0qKSyHlZpKvl"
   },
   "outputs": [],
   "source": [
    "#### Fixing income formatting related value errors\n",
    "dfs[\"MSOA_INCOME_2018_mod\"][\"Total annual income (Ł)\"] = dfs[\"MSOA_INCOME_2018_mod\"][\"Total annual income (Ł)\"].str.replace(\",\", \"\").map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_INCOME_2018_mod\"].rename(columns = {\"MSOA code\": \"msoa11cd\", \"Region name\": \"region_name\", \"Total annual income (Ł)\": \"total_annual_income\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msoa11cd</th>\n",
       "      <th>region_name</th>\n",
       "      <th>total_annual_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>E02000166</td>\n",
       "      <td>London</td>\n",
       "      <td>52900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>E02000167</td>\n",
       "      <td>London</td>\n",
       "      <td>68200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>E02000168</td>\n",
       "      <td>London</td>\n",
       "      <td>57000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msoa11cd region_name  total_annual_income\n",
       "4000  E02000166      London                52900\n",
       "4001  E02000167      London                68200\n",
       "4002  E02000168      London                57000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"MSOA_INCOME_2018_mod\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining average rent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = requests.get(urls['LSOA_AVERAGE_RENTS'], headers = faking_browser).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_buff = io.BytesIO(raw_data)\n",
    "excel_file = pd.ExcelFile(io_buff)\n",
    "excel_file.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS'] = excel_file.parse('Raw data', skiprows = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'] = dfs['LSOA_AVERAGE_RENTS'][dfs['LSOA_AVERAGE_RENTS'][\"Year\"] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'][\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'].groupby(by=\"Category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'] = dfs['LSOA_AVERAGE_RENTS_MOD'][[\"Code\", \"Category\",\"Average\"]][dfs['LSOA_AVERAGE_RENTS_MOD'][\"Category\"] == \"All categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'].drop(columns = [\"Category\"], inplace = True)\n",
    "dfs['LSOA_AVERAGE_RENTS_MOD'].columns = [\"lad17cd\", \"average_rent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining output area code mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING\"] = pd.read_csv(urls['MSOA_TO_LSOA_MAPPING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"] = dfs[\"MSOA_TO_LSOA_MAPPING\"][[\"LAD17CD\", \"MSOA11CD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"] = dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"].rename(columns = {\"LAD17CD\": \"LAD17CD\".lower(), \"MSOA11CD\": \"MSOA11CD\".lower()}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging \"average rent\" and \"msoa to lsoa mapping\" dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'] = dfs['LSOA_AVERAGE_RENTS_MOD'].merge(dfs[\"MSOA_TO_LSOA_MAPPING_MOD\"], how = \"left\", left_on = \"lad17cd\", right_on = \"lad17cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['LSOA_AVERAGE_RENTS_MOD'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMaRTsI1kGPb"
   },
   "source": [
    "## Obtaining the weighted centroid locations of the MSOAs in the UK\n",
    "Since the found dataset is provided in JSON format, this acquisition process was a bit different. Pandas' json_normlaize was used to facilitate data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlYwdhA_kRSW",
    "outputId": "d4306345-5251-42c5-90c8-436aee9eea12"
   },
   "outputs": [],
   "source": [
    "dfs[\"MSOA_POP_WEIGHTED_COORDS\"] = json_normalize(requests.get(urls[\"MSOA_POP_WEIGHTED_COORDS\"]).json()[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZFcPER9kV_c"
   },
   "source": [
    "### Filtering the dataframe to relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "JOxcmH1VkWHo",
    "outputId": "5ee4a330-fc6a-401d-f196-0c629f8c1e8d"
   },
   "outputs": [],
   "source": [
    "dfs[\"MSOA_POP_WEIGHTED_COORDS_mod\"] = dfs[\"MSOA_POP_WEIGHTED_COORDS\"].drop(columns = [\"type\"])\n",
    "dfs[\"MSOA_POP_WEIGHTED_COORDS_mod\"].columns = list(c.split(\".\")[1] for c in dfs[\"MSOA_POP_WEIGHTED_COORDS_mod\"].columns)\n",
    "dfs[\"MSOA_POP_WEIGHTED_COORDS_mod\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYqergsZor-Z"
   },
   "source": [
    "## Merging the obtained DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcIES4XQoyHv"
   },
   "outputs": [],
   "source": [
    "dfs[\"all\"] = dfs[\"MSOA_INCOME_2018_mod\"].merge(\n",
    "    dfs[\"MSOA_POP_WEIGHTED_COORDS_mod\"], how = \"left\", left_on = \"msoa11cd\", right_on = \"msoa11cd\").merge(\n",
    "    dfs[\"MSOA_ETH_2011_mod\"], how = \"left\", left_on = \"msoa11cd\", right_on = \"msoa11cd\").merge(\n",
    "    dfs['LSOA_AVERAGE_RENTS_MOD'], how = \"left\",  left_on = \"msoa11cd\", right_on = \"msoa11cd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPrAu2ghpl_a",
    "outputId": "08538b35-7b24-47a4-b751-5b0a31296a86"
   },
   "outputs": [],
   "source": [
    "dfs[\"all\"].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeYLW7xzpkNw"
   },
   "outputs": [],
   "source": [
    "#### A bit of tidying up...removing duplicate columns\n",
    "dfs[\"all\"].drop(columns = [\"objectid\", \"type\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_ZAfEoTqEKM",
    "outputId": "2c70869d-fb59-4010-f8f7-b6e74043584e"
   },
   "outputs": [],
   "source": [
    "#### Checking for join fails -> counting null values for each column\n",
    "dfs[\"all\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housekeeping: deleting dataframes that are no longer used to reduce the notebook's size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = list(dfs.keys())\n",
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in all_keys:\n",
    "    if(k!=\"all\"):\n",
    "        del dfs[k]\n",
    "del io_buff\n",
    "del raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCFYAGO-qavn"
   },
   "source": [
    "## Obtaining geographical data for Chloropeth visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71S8U-kAqllC",
    "outputId": "94e44351-05cd-473c-9381-5694f0637ec5"
   },
   "outputs": [],
   "source": [
    "#### Checking the Geo Json file's structure to find the key to be matched on!\n",
    "json_response = requests.get(urls[\"MSOA_GSON\"]).json()\n",
    "json_response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bRYhNkJ0q2aQ",
    "outputId": "98589666-6523-44aa-a8d7-251c1e9897bb"
   },
   "outputs": [],
   "source": [
    "json_response[\"features\"][0][\"properties\"][\"msoa11cd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4ZLkA65rBMZ"
   },
   "source": [
    "### Filtering the retrieved Geo JSON to locations within London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOHbY9ICF10J"
   },
   "outputs": [],
   "source": [
    "def add_msoa_markers(passed_map, dfs_all, key_attribute_col):\n",
    "  for i in dfs_all.index:\n",
    "    row = dfs_all.loc[i]\n",
    "    loc = row[\"coordinates\"]\n",
    "    msoa11nn = row[\"msoa11nm\"]\n",
    "    msoa11cd = row[\"msoa11cd\"]\n",
    "    key_attribute_value = row[key_attribute_col] \n",
    "    pop = \"{} ({})\\n{}: {}\".format(msoa11nn, msoa11cd, key_attribute_col, key_attribute_value)\n",
    "    folium.Marker([loc[1], loc[0]],\n",
    "                        radius = 5,\n",
    "                        popup= pop                   \n",
    "                        ).add_to(passed_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(dfs[\"all\"].loc[0].to_dict()[\"asian_hospitality_percentage\"], np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_geo_json_with_tooltip(json_response_backup, unique_msoa_codes, dfs_all = None, dfs_tooltip_cols = None, tooltip_name = None):\n",
    "    \n",
    "    filtered_list = list()\n",
    "    \n",
    "    for row in json_response[\"features\"]:\n",
    "        current_msoa11cd = row[\"properties\"][\"msoa11cd\"]\n",
    "        \n",
    "        if current_msoa11cd in unique_msoa_codes:\n",
    "            tooltip_temp = \"MSOA ID: {} MSOA name:{}<br>\"\\\n",
    "            .format(row[\"properties\"][\"msoa11cd\"], row[\"properties\"][\"msoa11nm\"])\n",
    "            \n",
    "            if((dfs_all is not None) and (dfs_tooltip_cols is not None)):\n",
    "                if not isinstance(dfs_tooltip_cols, list):\n",
    "                    dfs_tooltip_cols = [dfs_tooltip_cols]\n",
    "                boolean_mask = dfs_all[\"msoa11cd\"] == current_msoa11cd\n",
    "                row_dict = dfs_all[boolean_mask].to_dict(orient = \"list\")\n",
    "                for dfs_tooltip_col in dfs_tooltip_cols:\n",
    "                    dfs_tooltip_val = row_dict[dfs_tooltip_col][0]\n",
    "                    float_formatter = \"{:.5f}\" if isinstance(dfs_tooltip_val, np.float) else \"{}\"\n",
    "                    to_be_formatted = \"{}: \" + float_formatter +\"<br>\"\n",
    "                    tooltip_temp += to_be_formatted.format(dfs_tooltip_col, dfs_tooltip_val)\n",
    "                if tooltip_name is not None:\n",
    "                    row[\"properties\"][tooltip_name] = tooltip_temp\n",
    "                else:\n",
    "                    row[\"properties\"][dfs_tooltip_col[0]] = tooltip_temp\n",
    "            else:\n",
    "                row[\"properties\"][\"tooltip\"] = tooltip_temp\n",
    "            filtered_list.append(row)\n",
    "            \n",
    "    print(len(filtered_list))\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_codes = dfs[\"all\"][\"msoa11cd\"].unique()\n",
    "filtered_list  = filter_geo_json_with_tooltip(json_response, MSOA_codes, dfs_all = dfs[\"all\"], dfs_tooltip_cols = 'total_annual_income')\n",
    "json_response[\"features\"] = filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88xTJg1SrXh3"
   },
   "outputs": [],
   "source": [
    "#### Reassigning the features key value so that metadata does not have to be redefined.\n",
    "json_response[\"features\"]= filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response[\"features\"][0][\"properties\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pjeMVQluVtN"
   },
   "source": [
    "## Plotting the Income by MSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "wivng08FWNFQ",
    "outputId": "6a39247d-2e85-4fe8-b273-2f19ee49cdf3"
   },
   "outputs": [],
   "source": [
    "ax = dfs[\"all\"].sort_values(by='total_annual_income', ascending = False)\\\n",
    ".head(30)\\\n",
    ".plot(x ='msoa11nm',\n",
    "      y = 'total_annual_income',\n",
    "      kind = \"bar\",\n",
    "      label = \"Household income\")\n",
    "ax.set_title(\"The top 30 MSOA areas based on Total annual income\")\n",
    "ax.set_xlabel(\"MSOA\")\n",
    "ax.set_ylabel(\"Total income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqBMRqe-daOR"
   },
   "source": [
    "### Chloropeth map of Total income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi7cTkn4uiC9"
   },
   "outputs": [],
   "source": [
    "maps[\"base_map\"] = lambda : folium.Map(LONDON_COORDS, zoom_start = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmXOZjTb80Qx"
   },
   "outputs": [],
   "source": [
    "maps[\"income_map\"] = maps[\"base_map\"]()\n",
    "maps[\"income_choro_layer\"] = folium.Choropleth(\n",
    "    data = dfs[\"all\"],\n",
    "    columns = [\"msoa11cd\", 'total_annual_income'],\n",
    "    geo_data = json_response,\n",
    "    key_on = \"feature.properties.msoa11cd\",\n",
    "    fill_color = \"YlOrRd\"\n",
    ")\n",
    "maps[\"income_choro_layer\"].add_to(maps[\"income_map\"])\n",
    "\n",
    "maps[\"gson_popup\"] = folium.features.GeoJsonTooltip(fields = [\"total_annual_income\"], labels = False)\n",
    "maps[\"income_choro_layer\"].geojson.add_child(maps[\"gson_popup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry788kgEA8hm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#maps[\"income_map\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJRpvXlyZeSz"
   },
   "source": [
    "## Plotting the MSOA's with the highest percentage of asian population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUmoaJ1HcNPa"
   },
   "outputs": [],
   "source": [
    "ax = dfs[\"all\"]\\\n",
    ".sort_values(by = \"asian_population_percentage\",\n",
    "             ascending = False)\\\n",
    "             .head(30)\\\n",
    "             .plot(x = \"msoa11nm\", y = \"asian_population_percentage\", kind = \"bar\", label = \"Asian percentage\")\n",
    "ax.set_ylabel(\"Ethnicity percentage\")\n",
    "ax.set_xlabel(\"MSOA\")\n",
    "ax.set_title(\"Top 30 MSOA based on the percentage of asian population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBfPxV14dhrM"
   },
   "source": [
    "### Chloropeth map of asian population's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_codes = dfs[\"all\"][\"msoa11cd\"].unique()\n",
    "filtered_list  = filter_geo_json_with_tooltip(json_response, MSOA_codes, dfs_all = dfs[\"all\"], dfs_tooltip_cols = \"asian_population_percentage\")\n",
    "json_response[\"features\"] = filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcTbWQNEw4nP"
   },
   "outputs": [],
   "source": [
    "maps[\"selected_eth_choro_layer\"] = folium.Choropleth(\n",
    "    data = dfs[\"all\"],\n",
    "    columns = [\"msoa11cd\", \"asian_population_percentage\"],\n",
    "    geo_data = json_response,\n",
    "    key_on = \"feature.properties.msoa11cd\",\n",
    "    fill_color = \"YlOrRd\"\n",
    ")\n",
    "maps[\"selected_eth_choro_layer\"].geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(fields = [\"asian_population_percentage\"], labels = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2 = maps['base_map']()\n",
    "m2 = m2.add_child(maps[\"selected_eth_choro_layer\"])\n",
    "#m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG9lUT68dSjR"
   },
   "source": [
    "## FourSquare Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSwlVxk5eRhK"
   },
   "source": [
    "### FourSquare helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iMz4ybFdWYK"
   },
   "outputs": [],
   "source": [
    "#### Requesting data for one specific location on the map.\n",
    "\n",
    "def explore_area_nearby(client_id, client_secret, access_token, lat, lng, radius = 500, limit = 100):\n",
    "    version = '20180605' # Foursquare API version\n",
    "    base_url_template = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&oauth_token={}&v={}&radius={}&limit={}'\n",
    "    lat_lng_suffix = \"&ll={},{}\"\n",
    "    base_url = base_url_template.format(client_id, client_secret, access_token, version, radius, limit)\n",
    "    request_url = base_url + lat_lng_suffix.format(lat, lng)\n",
    "    #print(request_url)\n",
    "    resp = requests.get(request_url)\n",
    "    return resp.json()\n",
    "\n",
    "#### Helper wrapper function to be used for the function above (\"explore_area_nearby\")\n",
    "\n",
    "def get_fs_for_latlng(data, raw = False):\n",
    "    lat_lng = data\n",
    "    client_id = \"OCJNVVQEBW4JMRT1XQWOMUA4D3BSVJ1ABPSFVWIGNQZ4MHKT\"\n",
    "    client_secret = \"4XAPAWARYQL5Y0OLDVCABVNFTC5SXUUH4Q0YYVVHSHNJJ44F\"\n",
    "    access_token = \"N2LGNKF1ZJBDYCFOYITCMFEUSMFYEXSZWEOEG2TNH15H1GEC\"\n",
    "    radius = 1000\n",
    "    limit = 500\n",
    "    raw_response = explore_area_nearby(client_id, client_secret, access_token, lat_lng[1], lat_lng[0], radius, limit)\n",
    "    if(raw):\n",
    "        return raw_response\n",
    "    \n",
    "    return raw_response[\"response\"][\"groups\"][0][\"items\"]\n",
    "\n",
    "#### Helper functions to extract relevant fields from the JSON response of FourSquare's API\n",
    "\n",
    "def get_venue_category(i, raw_response):\n",
    "    return raw_response[\"response\"][\"groups\"][0][\"items\"][i][\"venue\"][\"categories\"][0][\"name\"]\n",
    "\n",
    "    \n",
    "def get_venue_type(i, raw_response):\n",
    "    return raw_response[\"response\"][\"groups\"][0][\"items\"][i][\"reasons\"][\"items\"][0][\"type\"]\n",
    "\n",
    "def get_venue_name(i, raw_response):\n",
    "    return raw_response[\"response\"][\"groups\"][0][\"items\"][i][\"venue\"][\"name\"]\n",
    "\n",
    "def get_venue_lat_lng(i, raw_response):\n",
    "        return [raw_response[\"response\"][\"groups\"][0][\"items\"][i][\"venue\"][\"location\"][\"lat\"], \n",
    "                raw_response[\"response\"][\"groups\"][0][\"items\"][i][\"venue\"][\"location\"][\"lng\"]]\n",
    "\n",
    "#### Placing the above functions into a dictionary for programming convenience\n",
    "venue_extractor_functions = dict(venue_name = get_venue_name, \n",
    "                                 venue_location = get_venue_lat_lng,\n",
    "                                 venue_type =  get_venue_type, \n",
    "                                 venue_category = get_venue_category)\n",
    "\n",
    "#### Function to be used in a loop to extract each selected relevant field with one of the above functions\n",
    "\n",
    "def get_venue_fields(raw_response, venue_field_extractor_function):\n",
    "    extracted_fields = []\n",
    "    for i in range(0, len(raw_response[\"response\"][\"groups\"][0][\"items\"])):\n",
    "        extracted_fields.append(venue_field_extractor_function(i, raw_response))\n",
    "    return extracted_fields\n",
    "\n",
    "#### Since FourSquare's free tier only allows for 500 requests within an hour \n",
    "#### and rejects calls with the same API credentials in the next 2 hours,\n",
    "#### the helper function below aims to automatize this waiting process\n",
    "\n",
    "def patient_foursquare_calls(dfs):\n",
    "    #### Venue dataframe template\n",
    "    venue_ds_template = dict(venue_name = \"\", venue_location = \"\", venue_type = \"\", venue_category = \"\")\n",
    "\n",
    "    #### the dataframe to hold the extracted fields, each identified by its MSOA ID.\n",
    "\n",
    "    dfs[\"venue_df\"] = pd.DataFrame([], columns = [\"msoa_id\", \"venue_name\", \"venue_location\", \"venue_category\", \"venue_type\"])\n",
    "\n",
    "    #### Due to the aforementioned limitation of FourSquare's free tier, raw responses are decieded\n",
    "    #### to be saved in a serialized format,\n",
    "    #### should additional data be intended to be extracted.\n",
    "\n",
    "    raw_responses = []\n",
    "    data_length = len(dfs[\"all\"].index)\n",
    "    i = 0\n",
    "    #### Main loop to iterate through each MSOA center within the dataframe.\n",
    "\n",
    "    while(i < data_length):\n",
    "        try:\n",
    "            msoa_id =  dfs[\"all\"].loc[i, \"msoa11cd\"]\n",
    "\n",
    "            #### Getting the raw response data for the location\n",
    "            raw_response = get_fs_for_latlng(dfs[\"all\"].loc[i, \"coordinates\"], raw = True)\n",
    "            raw_responses.append(raw_response)\n",
    "            venue_ds_temp = venue_ds_template.copy()\n",
    "            for k,v in venue_extractor_functions.items():\n",
    "                temp_list =  get_venue_fields(raw_response, v)\n",
    "                venue_ds_temp[k] = temp_list\n",
    "            venue_ds_temp[\"msoa_id\"] = [msoa_id for i in range(0, len(temp_list))]\n",
    "            dfs[\"venue_df\"] = dfs[\"venue_df\"].append(pd.DataFrame(venue_ds_temp))\n",
    "            print(\"\\rPulled data for {:d}/{:d}. Last MSOID: {:s}\".format(i+1, data_length, msoa_id))\n",
    "            i+=1\n",
    "        except:\n",
    "            print(\"*\"*50 + \"\\nI will go to sleep for 2 hours since have reached the limit of FourSquare's free tier.\\n\" + \"*\"*50)\n",
    "            time.sleep(60*60*2+10)\n",
    "    return raw_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #patient_foursquare_calls(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the requested FourSquare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"] = pd.read_csv(\"fsquare_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"].rename(columns = {\"msoa_id\": \"msoa11cd\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"][\"venue_category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask_asian = dfs[\"foursquare_data\"][\"venue_category\"].str.match(re.compile(\".*(cambodian|korea|japanese|chinese|asian|vietnamese|thai|laos|Taiwan).*(restaurant|pub).*\",  re.IGNORECASE))\n",
    "boolean_mask_asian.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask_hosp = dfs[\"foursquare_data\"][\"venue_category\"].str.match(re.compile(\".*(restaurant|pub|food|takeaway).*\",  re.IGNORECASE))\n",
    "boolean_mask_hosp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"][boolean_mask_asian].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_gb = dfs[\"foursquare_data\"][boolean_mask_asian].groupby(by=\"msoa11cd\").count().reset_index()\n",
    "asian_gb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"foursquare_data\"][boolean_mask_hosp].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_gb = dfs[\"foursquare_data\"][boolean_mask_hosp].groupby(by=\"msoa11cd\").count().reset_index()\n",
    "hosp_gb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_gb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_asian_hosp = asian_gb[[\"msoa11cd\", \"venue_name\"]]\\\n",
    ".rename(columns = {\"venue_name\": \"asian_hospitality_count\"})\\\n",
    ".merge(hosp_gb[[\"msoa11cd\", \"venue_name\"]].rename(columns = {\"venue_name\": \"all_hospitality_count\"}),\n",
    "       how = \"left\",\n",
    "       left_on = \"msoa11cd\",\n",
    "       right_on = \"msoa11cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_asian_hosp[\"asian_hospitality_percentage\"] = aggr_asian_hosp[\"asian_hospitality_count\"] / aggr_asian_hosp[\"all_hospitality_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_asian_hosp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the retrieved FourSquare data with the main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"] = dfs[\"all\"].merge(aggr_asian_hosp, how = \"left\", left_on = \"msoa11cd\", right_on=\"msoa11cd\")\n",
    "dfs[\"all\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].drop(columns = [\"all_hospitality_count\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"] = dfs[\"all\"].merge(hosp_gb[[\"msoa11cd\", \"venue_type\"]], how = \"left\")\n",
    "dfs[\"all\"].rename(columns = {\"venue_type\": \"all_hospitality_count\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"][\"pop_relative_hospitality_frequency\"] = dfs[\"all\"][\"all_hospitality_count\"] / dfs[\"all\"][\"total_population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list  = filter_geo_json_with_tooltip(json_response, MSOA_codes, dfs_all = dfs[\"all\"], dfs_tooltip_cols = \"asian_hospitality_percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the relative ratio of asian hospitality facilities by MSOA in a Choloropeth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[\"asian_frequency\"] = maps[\"base_map\"]()\n",
    "maps[\"asian_frequency_choropleth\"] = folium.Choropleth(geo_data = json_response , \n",
    "                                                       data = dfs[\"all\"], \n",
    "                                                       columns = [\"msoa11cd\", \"asian_hospitality_percentage\"],\n",
    "                                                       key_on = \"feature.properties.msoa11cd\",\n",
    "                                                       fill_color = \"BuPu\")\n",
    "maps[\"asian_frequency_choropleth\"].geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(label = False, fields = [\"asian_hospitality_percentage\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps[\"asian_frequency_choropleth\"].add_to(maps[\"asian_frequency\"])\n",
    "#maps[\"asian_frequency\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orltHnJHt2Wp"
   },
   "source": [
    "<h2 id=\"Analysing-each-MSOA-by-the-relative-frequency-of-the-restaurants-serving-meals-of-the-selected-cuisine\">Analysing each MSOA by the relative frequency of the restaurants serving meals of the selected cuisine w.r.t. the frequency of other restaurants....<br /><br /></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing clustering tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hopkins_statistics(dataset, sample_percentage = 0.1):\n",
    "\n",
    "    np.random.seed(0)\n",
    "    ds_shape = dataset.shape\n",
    "\n",
    "    sample_size = int(ds_shape[0] * sample_percentage)\n",
    "    \n",
    "    artificial_ds = np.random.uniform(np.amin(dataset, axis = 0), np.amax(dataset, axis = 0), size = [sample_size, ds_shape[1]])\n",
    "\n",
    "    sample_indices = np.random.choice(range(0, ds_shape[0]), sample_size)\n",
    "    ds_samples = dataset[sample_indices]\n",
    "\n",
    "    m = NearestNeighbors().fit(dataset)\n",
    "    \n",
    "    u_dist, _ = m.kneighbors(artificial_ds, n_neighbors = 2, return_distance = True)\n",
    "    w_dist, _ = m.kneighbors(ds_samples, n_neighbors = 2, return_distance = True)\n",
    "    \n",
    "    # Why n_neighbors = 2?\n",
    "    # If n_neighbors = 1 is given, instead of a calculated distance as one sum it returns the distance dimensionwise\n",
    "    \n",
    "    # For w_dist it is the second neighbor, hence the 1th index. \n",
    "    # The first neighbour is the data point itself since it has been sampled from the dataset.\n",
    "    # For u_dist, it is the first neighbor (hence the 0th index), because\n",
    "    # the artificial datapoints are assumed to be not part of the original dataset.\n",
    "\n",
    "    w_dist = w_dist[:,1]\n",
    "    u_dist = u_dist[:, 0]\n",
    "    return np.sum(u_dist)/(np.sum(w_dist) + np.sum(u_dist))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the clustering tendency of the real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_columns = [\"total_annual_income\",\n",
    "                            \"asian_population_percentage\",\n",
    "                            \"asian_hospitality_percentage\",\n",
    "                            \"pop_relative_hospitality_frequency\",\n",
    "                            \"average_rent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data_for_hopkins_statistics = dfs[\"all\"]\\\n",
    "[selected_feature_columns].values\n",
    "column_data_for_hopkins_statistics = StandardScaler().fit_transform(column_data_for_hopkins_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data_for_hopkins_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hopkins_statistics(column_data_for_hopkins_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins(column_data_for_hopkins_statistics,110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM47OjtausQ3"
   },
   "source": [
    "# Finding the optimal K for clustering\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(3,11))\n",
    "\n",
    "visualizer.fit(X)\n",
    "visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kays = list(range(2, 20))\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_scores = []\n",
    "wss_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in kays:\n",
    "    model = KMeans(init = \"k-means++\", random_state = 0, n_init = 500, n_clusters = i)\n",
    "    model.fit(column_data_for_hopkins_statistics)\n",
    "    silhouette_scores.append(silhouette_score(column_data_for_hopkins_statistics, model.labels_, metric = 'euclidean'))\n",
    "    wss_scores.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "silhouette_scores_hat = MinMaxScaler().fit_transform(np.array(silhouette_scores).reshape(18,1))\n",
    "wss_scores_hat =  MinMaxScaler().fit_transform(np.array(wss_scores).reshape(18,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(kays, silhouette_scores_hat, label = \"Silhouette scores\")\n",
    "ax.plot(kays, wss_scores_hat, label = \"Within Cluster Sum of Squares\")\n",
    "ax.plot([4,4], [0,1.2], label = \"Identified ideal K number\")\n",
    "ax.set_xticks(list(range(1,21)))\n",
    "ax.set_xlabel(\"Number of K\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(init = \"k-means++\", random_state = 0, n_init = 500, n_clusters = 4)\n",
    "model.fit(column_data_for_hopkins_statistics)\n",
    "dfs[\"all\"][\"cluster\"] = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the optimal clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_columns.append(\"cluster\")\n",
    "selected_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"][selected_feature_columns].groupby(by=\"cluster\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"all\"][selected_feature_columns].groupby(by=\"cluster\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjq5nQ6u_QE"
   },
   "source": [
    "# Visualise clusters on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list  = filter_geo_json_with_tooltip(json_response,\n",
    "                                              MSOA_codes,\n",
    "                                              dfs_all = dfs[\"all\"], \n",
    "                                              dfs_tooltip_cols = selected_feature_columns,\n",
    "                                                tooltip_name = \"comprehensive\")\n",
    "json_response[\"features\"] = filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_map = maps['base_map']()\n",
    "final_choro = folium.Choropleth(\n",
    "    data = dfs[\"all\"],\n",
    "    geo_data = json_response,\n",
    "    columns = [\"msoa11cd\", \"cluster\"],\n",
    "    key_on = \"feature.properties.msoa11cd\",\n",
    "    fill_color = \"BuPu\")\n",
    "tooltips = folium.features.GeoJsonTooltip(fields = [\"comprehensive\"], labels = False)\n",
    "\n",
    "final_choro.geojson.add_child(\n",
    "      tooltips  \n",
    ")\n",
    "final_map.add_child(final_choro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oC4m9EyJbTQr",
    "eSwlVxk5eRhK",
    "orltHnJHt2Wp"
   ],
   "name": "MSOA_SEGMENTATION_OF_LONDON_TO_AID_DECISION_MAKING_IN_CHOOSING_RESTAURANT_LOCATION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
